{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Super-Resolution to Sentinel-2 Imagery\n",
        "### Alexander Vu and Benjamin Gaskill\n",
        "---"
      ],
      "metadata": {
        "id": "Lee9ogEeD6Iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Description**\n",
        "### The goal of our project is to research, adapt, and fine-tune multiple pre-existing super-resolution deep learning frameworks to resample Sentinel-2 imagery from its native resolution of 10 meters up to 1.5 meters per pixel. Our main focus is on the WorldStrat super-resolution model, which we will test using multi-temporal stacks of input imagery for 6 selected sites across Zambia. The model accepts a multi-temporal stack of 8 images, along with all 12 bands of Sentinel 2. The WorldStrat model will be adapted to our needs and integrated with any additional models we find.\n",
        "\n",
        "### We will develop an imagery acquisition and preprocessing script and feed the input images into the model. To assess the performance of the model, the super-resolution outputs will be compared against Planet imagery and high-resolution imagery located at the same test sites. We will visualize the original 10-meter bands upscaled to 1.5 meters, namely the red, blue, green, and near infrared bands. We hope that our model can be utilized by the Agricultural Impacts Research Group to serve as a complement to paid high-resolution imagery such as Planet.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1zr6PdHjEGtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Division of Labor**\n",
        "### Ben is responsible for developing a data acquisition and pre-processing pipeline for Sentinel 2 imagery. This notebook connects to Google Earth Engine and samples 6 bounding boxes within Zambia. 3 samples represent mixed urban areas, and 3 samples represent rural areas. By sampling geographically diverse areas, we hope to capture finer-grain details for our model to perform more effectively. The script processes cloud-free composites for 2024 by selecting imagery with less than 5 percent cloud coverage and masking cloudy pixels with the Scene Classification Layer. The script also uses Sentinel-2 footprints to ensure that each study area falls fully within one footprint and that there is valid data for the entire extent. The layers are then exported as GeoTiff files. Ben will also test the model on more geographically distinct areas outside of Zambia, to assess the ability of the model to work well in any region.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Alex is responsible for testing the WorldStrat super-resolution model using the pre-existing data in order to understand the input requirements. He will also be responsible for the inference pipeline, which will chip the input images, adapt them to the modelâ€™s input, and build the full super-resolution image. Then, the super-resolution image will be exported to a tiff file.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### We are both responsible for researching additional super-resolution models and will jointly work on adapting and fine-tuning them to create a custom super-resolution deep learning framework. We will then both compare the performance of our chosen models against existing high-resolution products on different geographies.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "8GrRFtLNEaEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Key Findings**\n",
        "### So far, we have found that the model performs reasonably well. Multiple iterations of the image acquisition and processing pipeline had to be created, with new requirements and refinements as we continued to test and understand the model. Further work is required to fix issues with spatial location, scaling, and overlap of the super-resolution output.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6J1tzHU0mOZv"
      }
    }
  ]
}